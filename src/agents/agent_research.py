from langchain_core.messages import ToolMessage, AIMessage, HumanMessage
from langgraph.graph import END
from langgraph.types import Command
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from config.models import get_llm, get_tavily_client
from src.graph.state import State


llm = get_llm()

web_search_tool = get_tavily_client()

tools = [web_search_tool]

llm_with_tools = llm.bind_tools(tools)

prompt = ChatPromptTemplate.from_messages([
    ("system",
    """
    VocÃª Ã© um Agente de Pesquisa Escolar, um especialista em ajudar alunos a encontrar e entender informaÃ§Ãµes para seus trabalhos e estudos. Sua missÃ£o Ã© fornecer respostas precisas, bem explicadas e confiÃ¡veis.

    **Seu Processo de Trabalho:**
    1.  **Analise a Pergunta:** Leia a pergunta do aluno com atenÃ§Ã£o, considerando o histÃ³rico da conversa para entender o contexto completo.
    2.  **Avalie seu Conhecimento:** Antes de responder, faÃ§a uma autoavaliaÃ§Ã£o. A pergunta exige fatos, datas, nomes especÃ­ficos, estatÃ­sticas ou informaÃ§Ãµes sobre eventos recentes? VocÃª tem 100% de certeza da resposta?
    3.  **Use a Ferramenta se NecessÃ¡rio:** Se a resposta for "sim" para qualquer uma das questÃµes acima, ou se vocÃª tiver qualquer dÃºvida, Ã© **obrigatÃ³rio** usar sua ferramenta de pesquisa `web_search` para verificar e coletar informaÃ§Ãµes.
    4.  **Sintetize e Responda:** ApÃ³s a pesquisa, nÃ£o apenas entregue os dados. Sintetize os resultados, explique-os de forma clara e didÃ¡tica, e conecte-os com o que jÃ¡ foi discutido na conversa.
    5.  **Cite suas Fontes:** Ao final da resposta, inclua uma seÃ§Ã£o "Fontes:" com as URLs de onde a informaÃ§Ã£o foi retirada.
    6.  **REGRA FUNDAMENTAL:** ApÃ³s receber o resultado de uma `ToolMessage` (o resultado da sua pesquisa), sua Ãºnica e principal tarefa Ã© construir a resposta final para o usuÃ¡rio. **NÃƒO** use a ferramenta `web_search` novamente a menos que o usuÃ¡rio faÃ§a uma **nova pergunta** que exija informaÃ§Ãµes completamente diferentes.
   
    Sua ferramenta principal Ã©: `web_search`. Use-a sempre que a precisÃ£o for crucial.
    
    """),
    MessagesPlaceholder(variable_name="messages"),
])

llm_agent_research = prompt | llm_with_tools

def agent_research_node(state: State):
    
    print("\n=== agent_research_node ===")

    if state["messages"] and isinstance(state["messages"][-1], ToolMessage):
        messages_for_llm = state["messages"]
    else:
        messages_for_llm = state["messages"] + [HumanMessage(content=state["input"])]

    response = llm_agent_research.invoke({"messages": messages_for_llm})

    if response.tool_calls:
        return Command(
            goto="agent_tools_node",
            update={"messages_tools": [response]}
        )
    else:
        return Command(
            goto=END,
            update={
                "messages": state["messages"] + [AIMessage(content=response.content)]
            }
        )

def agent_tools_node(state: State):
    print("--- ðŸ› ï¸ NÃ“ DA FERRAMENTA ---")

    last_message = state["messages_tools"][-1]

    tool_messages = []
    for tool_call in last_message.tool_calls:
        print(f"  -> Chamando ferramenta '{tool_call['name']}' com args: {tool_call['args']}")

        result = web_search_tool.invoke(tool_call["args"])

        tool_messages.append(
            ToolMessage(content=str(result), tool_call_id=tool_call["id"])
        )

    return Command(
        goto="agent_research_node",  
        update={
            "messages": state['messages'] + [last_message] + tool_messages
        }
    )
